# Distributed Log Processing System

A production-grade distributed log processing system built with Spring Boot, Apache Kafka, Redis, and PostgreSQL. This system demonstrates real-world distributed system patterns for parsing, processing, and analyzing log data at scale.

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ
‚îÇLog Producer ‚îÇ ‚îÄ‚ñ∫ ‚îÇ   Kafka     ‚îÇ ‚îÄ‚ñ∫ ‚îÇLog Parser   ‚îÇ
‚îÇ   :8081     ‚îÇ    ‚îÇ   :9092     ‚îÇ    ‚îÇ   :8082     ‚îÇ
‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
                   ‚îÇ             ‚îÇ             ‚îÇ
                   ‚îÇ   Redis     ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ   :6379     ‚îÇ             
                   ‚îÇ             ‚îÇ             
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             
                                               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ             ‚îÇ
‚îÇAPI Gateway  ‚îÇ ‚óÑ‚îÄ ‚îÇ PostgreSQL  ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ   :8080     ‚îÇ    ‚îÇ   :5432     ‚îÇ             
‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ             
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             

       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ
‚îÇ Prometheus  ‚îÇ    ‚îÇ  Grafana    ‚îÇ
‚îÇ   :9090     ‚îÇ    ‚îÇ   :3000     ‚îÇ
‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Services Overview

- **Log Producer** (Port 8081): Generates sample Apache/Nginx logs and publishes to Kafka
- **Log Parser** (Port 8082): Consumes raw logs, parses structured data, handles failures
- **API Gateway** (Port 8080): REST API for querying parsed logs with analytics
- **Apache Kafka** (Port 9092): Message streaming platform for event-driven architecture
- **Redis** (Port 6379): Caching layer for parser state and performance optimization
- **PostgreSQL** (Port 5432): Persistent storage for parsed log events
- **Prometheus** (Port 9090): Metrics collection and monitoring
- **Grafana** (Port 3000): Metrics visualization and dashboards

## üöÄ Quick Start

### Prerequisites

- Java 17+
- Maven 3.6+
- Docker & Docker Compose
- 8GB+ RAM recommended

### 1. Clone and Setup

```bash
# The system files are already generated by the script
cd distributed-log-processor

# Start infrastructure and build applications
./setup.sh
```

### 2. Start Applications

```bash
# Terminal 1: Start Log Producer
java -jar log-producer/target/log-producer-1.0.0.jar

# Terminal 2: Start Log Parser  
java -jar log-parser/target/log-parser-1.0.0.jar

# Terminal 3: Start API Gateway
java -jar api-gateway/target/api-gateway-1.0.0.jar
```

### 3. Verify System Health

```bash
# Run integration tests
./integration-tests/integration-test.sh

# Check service health
curl http://localhost:8081/api/logs/health  # Producer
curl http://localhost:8082/actuator/health  # Parser
curl http://localhost:8080/api/logs/health  # Gateway
```

## üìä Monitoring & Analytics

### Grafana Dashboards
- **URL**: http://localhost:3000
- **Credentials**: admin/admin
- **Pre-configured dashboards**: Log processing metrics, parsing rates, error rates

### Prometheus Metrics
- **URL**: http://localhost:9090
- **Key metrics**: `logs_processed_total`, `log_parse_success_total`, `log_parse_failure_total`

### API Endpoints

```bash
# Get recent logs
curl "http://localhost:8080/api/logs?page=0&size=10"

# Filter by IP address
curl "http://localhost:8080/api/logs/ip/192.168.1.100"

# Filter by status code
curl "http://localhost:8080/api/logs/status/404"

# Get status code statistics
curl "http://localhost:8080/api/logs/stats/status-codes"

# Get hourly request counts
curl "http://localhost:8080/api/logs/stats/hourly"
```

## üî• Load Testing

Generate load to test system performance:

```bash
# Run load test (60 seconds, 5 concurrent workers)
./load-test.sh

# Custom load test
curl -X POST "http://localhost:8081/api/logs/send" \
  -H "Content-Type: text/plain" \
  -d '192.168.1.100 - - [27/Sep/2025:10:30:00 +0000] "GET /api/test HTTP/1.1" 200 1234'
```

## üè≠ Production Considerations

### Scalability Patterns Implemented

1. **Event-Driven Architecture**: Decoupled services using Kafka topics
2. **Horizontal Scaling**: Stateless services with partitioned data processing
3. **Circuit Breaker Pattern**: Resilience4j for external dependency failures
4. **Dead Letter Queue**: Failed parsing attempts isolated for analysis
5. **Distributed Caching**: Redis for shared parser state across instances

### Performance Optimizations

- **Kafka Partitioning**: Raw logs distributed across 3 partitions
- **Batch Processing**: Consumer batching for improved throughput
- **Connection Pooling**: Database and Redis connection pools
- **Compiled Regex**: Pre-compiled parsing patterns for performance
- **Async Processing**: Non-blocking I/O for external calls

### Error Handling & Resilience

- **Graceful Degradation**: System continues processing when enrichment services fail
- **Retry Mechanisms**: Configurable retry policies for transient failures
- **Health Checks**: Comprehensive health monitoring for all services
- **Metrics & Alerting**: Production-ready observability stack

## üîß Configuration

### Kafka Topics

- `raw-logs`: Incoming log entries (3 partitions)
- `parsed-events`: Successfully parsed structured data (3 partitions)  
- `parsing-dlq`: Failed parsing attempts for analysis (1 partition)

### Log Formats Supported

**Apache Common Log Format**:
```
192.168.1.100 - - [27/Sep/2025:10:30:00 +0000] "GET /api/users HTTP/1.1" 200 1234
```

**Nginx Combined Log Format**:
```
192.168.1.100 - - [27/Sep/2025:10:30:00 +0000] "GET /api/users HTTP/1.1" 200 1234 "-" "Mozilla/5.0..." rt=0.123
```

### Environment Variables

```bash
# Database
SPRING_DATASOURCE_URL=jdbc:postgresql://localhost:5432/logprocessor
SPRING_DATASOURCE_USERNAME=loguser
SPRING_DATASOURCE_PASSWORD=logpass

# Kafka
SPRING_KAFKA_BOOTSTRAP_SERVERS=localhost:9092

# Redis
SPRING_DATA_REDIS_HOST=localhost
SPRING_DATA_REDIS_PORT=6379
```

## üß™ Testing

### Unit Tests
```bash
mvn test
```

### Integration Tests
```bash
./integration-tests/integration-test.sh
```

### Load Tests
```bash
./load-test.sh
```

## üìà Scaling for Production

### Horizontal Scaling Strategy

1. **Log Parser Service**: Scale to 10+ instances based on Kafka lag
2. **API Gateway**: Scale based on query volume and response time
3. **Kafka Partitions**: Increase partitions for higher throughput
4. **Database**: Read replicas for analytics queries
5. **Redis**: Cluster mode for high availability

### Capacity Planning

- **Log Volume**: System tested up to 10K logs/second per parser instance
- **Storage**: PostgreSQL partitioning recommended for >1M logs/day
- **Memory**: 2GB+ heap per service recommended for production
- **Network**: Monitor Kafka network I/O for bottlenecks

### High Availability

- **Multi-AZ Deployment**: Deploy services across availability zones
- **Database Replication**: Master-slave PostgreSQL setup
- **Kafka Clustering**: 3+ broker cluster with proper replication
- **Load Balancing**: Multiple instances behind load balancers

## üõ†Ô∏è Troubleshooting

### Common Issues

**Kafka Connection Errors**:
```bash
# Check Kafka is running
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

**Database Connection Issues**:
```bash
# Check PostgreSQL connection
docker exec postgres psql -U loguser -d logprocessor -c "SELECT 1;"
```

**High Memory Usage**:
- Increase JVM heap: `-Xmx2g -Xms1g`
- Monitor garbage collection metrics
- Check for parser regex compilation overhead

### Monitoring Commands

```bash
# Check Kafka consumer lag
docker exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group log-parser-group

# Monitor Redis memory usage
docker exec redis redis-cli INFO memory

# Check database connections
docker exec postgres psql -U loguser -d logprocessor -c "SELECT COUNT(*) FROM pg_stat_activity;"
```

## üìö Learning Objectives Achieved

After completing this system, you understand:

‚úÖ **Event-driven architecture** patterns for distributed systems
‚úÖ **Kafka-based message streaming** for reliable data processing  
‚úÖ **Circuit breaker patterns** for resilient service interactions
‚úÖ **Distributed caching strategies** with Redis
‚úÖ **Production monitoring** with Prometheus and Grafana
‚úÖ **Horizontal scaling patterns** for stateless services
‚úÖ **Error handling and dead letter queues** for fault tolerance
‚úÖ **Performance optimization** techniques for high-throughput systems

## üéØ Next Steps

Tomorrow's lesson builds storage systems that handle petabyte-scale data with intelligent partitioning, compression, and retention policies - the foundation for Netflix-scale log analytics platforms.

---

Built with ‚ù§Ô∏è using Spring Boot, Kafka, Redis, PostgreSQL, and modern distributed system patterns.
